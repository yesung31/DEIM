eval_spatial_size: [644, 644] # h w  # Fit to patch size 14

DEIM:
  backbone: DINOv2

DINOv2:
  pretrained: True
  local_model_dir: dinov2/

HybridEncoder:
  in_channels: [384, 384, 384]
  feat_strides: [7, 14, 28]

DFINETransformer:
  feat_channels: [256, 256, 256]
  feat_strides: [7, 14, 28]

train_dataloader: 
  dataset: 
    transforms:
      ops:
        - {type: Mosaic, output_size: 320, rotation_range: 10, translation_range: [0.1, 0.1], scaling_range: [0.5, 1.5],
           probability: 1.0, fill_value: 0, use_cache: False, max_cached_images: 50, random_pop: True}
        - {type: RandomPhotometricDistort, p: 0.5}
        - {type: RandomZoomOut, fill: 0}
        - {type: RandomIoUCrop, p: 0.8}
        - {type: SanitizeBoundingBoxes, min_size: 1}
        - {type: RandomHorizontalFlip}
        - {type: Resize, size: [644, 644], }  # Fit to patch size 14
        - {type: SanitizeBoundingBoxes, min_size: 1}
        - {type: ConvertPILImage, dtype: 'float32', scale: True}
        - {type: ConvertBoxes, fmt: 'cxcywh', normalize: True}
  collate_fn:
    base_size: 644
    scale_size: 28

val_dataloader:
  dataset:
    transforms:
      ops:
        - {type: Resize, size: [644, 644], }
        - {type: ConvertPILImage, dtype: 'float32', scale: True}